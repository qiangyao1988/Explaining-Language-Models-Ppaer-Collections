#  Explaining Language Models Paper Collections
 This repo lists recent papers for Explaining Language Models.

- Shapley values

- Perturbation-based

- Gradient-based

  - **Discretized Integrated Gradients for Explaining Language Models** [[Paper]](https://arxiv.org/pdf/2108.13654.pdf)[[Code]](https://github.com/INK-USC/DIG)<br>Description: 

  - **Do Feature Attribution Methods Correctly Attribute Features?** [[Paper]](https://arxiv.org/pdf/2104.14403.pdf)[[Code]](https://github.com/YilunZhou/feature-attribution-evaluation)<br>Description: 

  - **Beyond Word Importance Contextual Decomposition to Extract Interactions from LSTMs** [[Paper]](https://arxiv.org/pdf/1801.05453.pdf)<br>Description: 

  - **Connecting Attributions and QA Model Behavior on Realistic Counterfactuals** [[Paper]](https://aclanthology.org/2021.emnlp-main.447.pdf)[[Code]](https://github.com/xiye17/EvalQAExpl)<br>Description: 

  - **Did the Model Understand the Question** [[Paper]](https://arxiv.org/pdf/1805.05492.pdf)<br>Description: 

  - **Hierarchical Neural Net Interpretations (ACD)** [[Paper]](https://arxiv.org/pdf/1806.05337.pdf)[[Code]](https://github.com/csinva/hierarchical-dnn-interpretations)<br>Description: 

  - **Connecting Attributions and QA Model Behavior on Realistic Counterfactuals** [[Paper]](https://arxiv.org/pdf/2104.04515.pdf)<br>Description: 

  - **Interpreting Convolutional Sequence Model by Learning Local Prototypes with Adaptation Regularization** [[Paper]](https://dl.acm.org/doi/pdf/10.1145/3459637.3482355?casa_token=8z1dQ2D1CsYAAAAA:71YXiECsS8IcHNi-4Eksyf0UeFDT8XQXG1QQyxndB371KgmhErkR8LNlQAp6qWXnmW5gfgslipw)<br>Description: 

  - **Attention Weights in Transformer NMT Fail Aligning Words Between Sequences but Largely Explain Model Predictions** [[Paper]](https://arxiv.org/pdf/2109.05853.pdf)<br>Description: 

  - **Rethinking Attention-Model Explainability through Faithfulness Violation Test** [[Paper]](https://arxiv.org/pdf/2201.12114.pdf)<br>Description: 
  
  - **Attention Weights in Transformer NMT Fail Aligning Words Between Sequences but Largely Explain Model Predictions** [[Paper]](https://arxiv.org/pdf/2109.05853.pdf)<br>Description: 
  
  - **Grad-CAM: Visual Explanations From Deep Networks via Gradient-Based Localization** [[Paper]](https://openaccess.thecvf.com/content_ICCV_2017/papers/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.pdf)<br>Description: 
  
  - **Explaining Information Flow Inside Vision Transformers Using Markov Chain** [[Paper]](https://openreview.net/pdf?id=TT-cf6QSDaQ)<br>Description: 
  
  - **Multi-Head Attention with Disagreement Regularization** [[Paper]](https://arxiv.org/pdf/1810.10183.pdf)<br>Description: 
  
  - **Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned** [[Paper]](https://arxiv.org/pdf/1905.09418.pdf?ref=https://githubhelp.com)<br>Description: 
  
  - **On Exploring Attention-based Explanation for Transformer Models in Text Classification** [[Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671639&casa_token=jZTxTSWcw68AAAAA:EOJF6h4voDY4l_E3WGVPaNEi3OkcX2m3yJpyGDIwb1IgH19KvZV08wm8uz7Exm7myWB2luc)<br>Description: 
  
  - **Mutual Information Preserving Back-propagation: Learn to Invert for Faithful Attribution** [[Paper]](https://dl.acm.org/doi/pdf/10.1145/3447548.3467310)<br>Description: 
  
  - **Self-Attention Attribution: Interpreting Information Interactions Inside Transformer**[[Paper]](https://www.aaai.org/AAAI21Papers/AAAI-10151.HaoY.pdf.pdf)<br>Description: 
  
  - **LRP-based Method for Transformer Interpretability**[[Paper]](https://openreview.net/pdf?id=rBHej2zm2AK)<br>Description: 
  
  - **Transformer Interpretability Beyond Attention Visualization**[[Paper]](https://openaccess.thecvf.com/content/CVPR2021/papers/Chefer_Transformer_Interpretability_Beyond_Attention_Visualization_CVPR_2021_paper.pdf)<br>Description: 
  
  - **Generic Attention-Model Explainability for Interpreting Bi-Modal and Encoder-Decoder Transformers**[[Paper]](https://openaccess.thecvf.com/content/ICCV2021/papers/Chefer_Generic_Attention-Model_Explainability_for_Interpreting_Bi-Modal_and_Encoder-Decoder_Transformers_ICCV_2021_paper.pdf)<br>Description: 
  
  - **XAI for Transformers Better Explanations through Conservative**[[Paper]](https://arxiv.org/pdf/2202.07304.pdf)<br>Description: 
  
  - **AllenNLP Interpret: A Framework for Explaining Predictions of NLP Models**[[Paper]](https://arxiv.org/pdf/1909.09251.pdf)<br>Description: 
  
  - **A Diagnostic Study of Explainability Techniques for Text Classification**[[Paper]](https://arxiv.org/pdf/2009.13295.pdf)<br>Description: 
  
  - **A General Taylor Framework for Unifying and Revisiting Attribution Methods**[[Paper]](https://arxiv.org/pdf/2105.13841.pdf)<br>Description: 
  
  - **Learning Important Features Through Propagating Activation Differences**[[Paper]](http://proceedings.mlr.press/v70/shrikumar17a/shrikumar17a.pdf)<br>Description: 
  
  - **Learning to Explain: An Information-Theoretic Perspective on Model Interpretation**[[Paper]](http://proceedings.mlr.press/v80/chen18j/chen18j.pdf.pdf)<br>Description: 
  
  - **Influence Patterns for Explaining Information Flow in BERT**[[Paper]](https://arxiv.org/pdf/2011.00740.pdf)<br>Description: 
  
    
    
    
    
    

